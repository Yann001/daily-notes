# 机器学习

> 周志华 著



## 第1章 绪论

### 1.1 引言

机器学习的主要内容是关于计算机上从数据中产生模型的算法，即学习算法。

模型，全局性结果（如一棵决策树）；模式，局部性结果（如一条规则）。

### 1.2 基本术语

数据集

示例（instance）或样本（sample），特征向量（feature vector）

属性（attribute）或特征（feature），属性值

属性空间，样本空间或输入空间

学习、训练

训练数据，训练样本，训练集

潜在规律：假设（hypothesis），模型，学习器

潜在规律自身：真相或真实（ground-truth）

标记（label），样例（example），标记空间

分类（classification），回归（regression）

二分类：正类（positive class），负类（negative class）

多分类（mutil-class classification）

聚类（clustering），簇（cluster），潜在划分

监督学习（supervised learning）：分类，回归

无监督学习（unsupervised learning）：聚类

泛化（generalization）：学得模型适用于新样本的能力



### 1.3 假设空间

归纳（induction），演绎（deduction）是科学推理的两大基本手段。



### 1.4 归纳偏好

奥卡姆剃刀（Occam's razor）

没有免费午餐定理（No Free Lunch Theorem）



### 1.5 发展历程



### 1.6 应用现状



### 1.7 阅读材料



## 第2章 模型评估与选择

### 2.1 经验误差与过拟合

分类错误的样本数占样本总数的比例称为“错误率”（error rate）。如果在m个样本中有a个样本分类错误，则错误率 $E=a/m$ ；相应地，$1-a/m$ 称为“精度”（accuracy）。

学习器的预测输出与样本真是输出之间的差异称为“误差”（error），学习器在训练集上的误差称为“训练误差”（training error）或“经验误差”（empirical error），在新样本上的物产称为“泛化误差”（generalization error）。

把训练样本自身的一些特点当做了所有样本都会具有的一般性质，会导致泛化性能下降，称为“过拟合”（overfitting），相对的是“欠拟合”（underfitting）。



### 2.2 评估方法

测试集（test set），测试误差（test error），分层采样（stratified sampling）

测试集应该尽可能与训练集互斥，即测试集本尽量不出现在训练集中，未在训练过程中使用过。

当只有一个包含m个样例的数据集D时，通过对D进行适当处理，从左产生出训练集S和测试集T，以下是几种处理方法：

1. 留出法，$D = S \cup T, S \cap T= \phi$ 。（常取2/3 ~ 4/5用于训练）

2. 交叉验证法（cross validation）（k折交叉验证）（常取k=10）

   特例：留一法（Leave One Out）

3. 自助法（bootstrapping）

**参数调节与最终模型**

参数调节（parameter tuning）



### 2.3 性能度量

性能度量（performance measure）：衡量模型泛化能力的评价标准。

1. 错误率与精度

2. 查准率（precision）、查全率（recall）与F1

   对于二分问题，可划分为真正例（true positive）、假正例（false positive）、真反例（true negative）、假反例（false positive）。

   分类结果混淆矩阵：

   | 真实情况 | 预测结果 |      |
   | ---- | ---- | ---- |
   |      | 正例   | 反例   |
   | 正例   | TP   | FN   |
   | 反例   | FP   | TN   |

   ​

